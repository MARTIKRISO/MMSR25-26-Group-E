{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluation (Precision)",
   "id": "640c1adcf416ab8e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-28T22:47:27.163878500Z",
     "start_time": "2025-12-28T22:47:26.452862400Z"
    }
   },
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from typing import Dict\n",
    "\n",
    "target_folder = 'MMSR25-26-Group-E'\n",
    "current_path = os.getcwd()\n",
    "\n",
    "while os.path.basename(current_path) != target_folder:\n",
    "    if os.path.basename(current_path) == 'RetrievalAlgorithm':\n",
    "        if os.path.join(current_path) not in sys.path:\n",
    "            sys.path.append(os.path.join(current_path))\n",
    "    parent = os.path.dirname(current_path)\n",
    "    os.chdir(parent)\n",
    "    current_path = parent\n",
    "print(current_path)\n",
    "\n",
    "\n",
    "from RetrievalAlgorithm.src.utils.per_query_metrics_evaluation import get_eval_metrics_for_each_query\n",
    "from EvaluationMetrics.src.data_loader import load_songs_data, get_genre_columns\n",
    "from EvaluationMetrics.src.metrics import precision_at_k"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\University\\7th_Semester\\MMSR25-26-Group-E\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T22:47:29.278558700Z",
     "start_time": "2025-12-28T22:47:27.179503300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "norm_names = ['max_abs', 'min_max', 'raw', 'robust', 'standard']\n",
    "eval_songs_df = load_songs_data()\n",
    "genres_columns = get_genre_columns()"
   ],
   "id": "2008bb7833ef82c3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Calculate Precision for each Track",
   "id": "8659c0fe670753a7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Unimodal",
   "id": "3b3d1b5c921efd74"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T22:47:29.310192500Z",
     "start_time": "2025-12-28T22:47:29.278558700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_unimodal_precision_dfs(feature_name: str = 'lyrics') -> Dict[str, pd.DataFrame]:\n",
    "    unimodal_precalculated_scores = dict()\n",
    "    precision_dfs = dict()\n",
    "\n",
    "    for norm_name in tqdm(norm_names, desc=f'Loading {feature_name} Precalculated scores'):\n",
    "        unimodal_precalculated_scores[norm_name]= pd.read_parquet(f'RetrievalAlgorithm/results/unimodal/{norm_name}/unimodal_{norm_name}_{feature_name}_similarity_scores.parquet')\n",
    "\n",
    "    print(f'Calculating {feature_name} Precision for each query ...')\n",
    "\n",
    "    for norm_name, precalculated_scores_df in unimodal_precalculated_scores.items():\n",
    "        print('='*100)\n",
    "        print('Normalization Name:', norm_name, '\\n')\n",
    "\n",
    "        precision_dfs[norm_name] = get_eval_metrics_for_each_query(\n",
    "            scores_df=precalculated_scores_df,\n",
    "            k_range=[5, 10, 20, 50, 100, 200],\n",
    "            genres_columns=genres_columns,\n",
    "            eval_songs_df=eval_songs_df,\n",
    "            metric_at_k=precision_at_k\n",
    "        )\n",
    "    return precision_dfs"
   ],
   "id": "465adf74d311d5a7",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Lyrics (BERT embeddings)",
   "id": "d8dcbfd03823bdd1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T22:53:27.123881900Z",
     "start_time": "2025-12-28T22:47:29.310192500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lyrics_precision_dfs = calculate_unimodal_precision_dfs(feature_name='lyrics')\n",
    "\n",
    "target_dir = 'RetrievalAlgorithm/results/unimodal'\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "for norm_name, feature_name, sim_scores_df in tqdm(lyrics_precision_dfs, desc='Saving Lyrics Precision scores'):\n",
    "    output_path = os.path.join(target_dir, norm_name)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    output_path = os.path.join(output_path, f'unimodal_{norm_name}_{feature_name}_precision.parquet')\n",
    "    sim_scores_df.to_parquet(output_path, index=False)\n",
    "del lyrics_precision_dfs"
   ],
   "id": "5db8344bbec36e25",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading lyrics Precalculated scores: 100%|██████████| 5/5 [00:08<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating lyrics Precision for each query ...\n",
      "====================================================================================================\n",
      "Normalization Name: max_abs \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   23.6s\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   28.0s\n",
      "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:   33.7s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:   40.5s\n",
      "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed:   48.9s\n",
      "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed:   56.0s\n",
      "[Parallel(n_jobs=4)]: Done 105 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 137 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 173 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=4)]: Done 213 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=4)]: Done 234 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=4)]: Done 257 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=4)]: Done 305 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=4)]: Done 330 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=4)]: Done 384 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=4)]: Done 413 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=4)]: Done 473 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=4)]: Done 504 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=4)]: Done 537 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=4)]: Done 570 tasks      | elapsed:  5.0min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m lyrics_precision_dfs = \u001B[43mcalculate_unimodal_precision_dfs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeature_name\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mlyrics\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m      3\u001B[39m target_dir = \u001B[33m'\u001B[39m\u001B[33mRetrievalAlgorithm/results/unimodal\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m      4\u001B[39m os.makedirs(target_dir, exist_ok=\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 14\u001B[39m, in \u001B[36mcalculate_unimodal_precision_dfs\u001B[39m\u001B[34m(feature_name)\u001B[39m\n\u001B[32m     11\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m'\u001B[39m\u001B[33m=\u001B[39m\u001B[33m'\u001B[39m*\u001B[32m100\u001B[39m)\n\u001B[32m     12\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m'\u001B[39m\u001B[33mNormalization Name:\u001B[39m\u001B[33m'\u001B[39m, norm_name, \u001B[33m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m'\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m14\u001B[39m     precision_dfs[norm_name] = \u001B[43mget_eval_metrics_for_each_query\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     15\u001B[39m \u001B[43m        \u001B[49m\u001B[43mscores_df\u001B[49m\u001B[43m=\u001B[49m\u001B[43mprecalculated_scores_df\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     16\u001B[39m \u001B[43m        \u001B[49m\u001B[43mk_range\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m20\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m50\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m200\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     17\u001B[39m \u001B[43m        \u001B[49m\u001B[43mgenres_columns\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgenres_columns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     18\u001B[39m \u001B[43m        \u001B[49m\u001B[43meval_songs_df\u001B[49m\u001B[43m=\u001B[49m\u001B[43meval_songs_df\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     19\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmetric_at_k\u001B[49m\u001B[43m=\u001B[49m\u001B[43mprecision_at_k\u001B[49m\n\u001B[32m     20\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     21\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m precision_dfs\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\University\\7th_Semester\\MMSR25-26-Group-E\\RetrievalAlgorithm\\src\\utils\\per_query_metrics_evaluation.py:74\u001B[39m, in \u001B[36mget_eval_metrics_for_each_query\u001B[39m\u001B[34m(scores_df, k_range, eval_songs_df, genres_columns, metric_at_k, n_jobs)\u001B[39m\n\u001B[32m     68\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m'\u001B[39m\u001B[33m-\u001B[39m\u001B[33m'\u001B[39m * \u001B[32m100\u001B[39m)\n\u001B[32m     69\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m'\u001B[39m\u001B[33mk =\u001B[39m\u001B[33m'\u001B[39m, k)\n\u001B[32m     71\u001B[39m tasks = [\n\u001B[32m     72\u001B[39m     (query_id, retrieved_list, k, eval_songs_df, genres_columns, metric_at_k)\n\u001B[32m     73\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m query_id, retrieved_list \u001B[38;5;129;01min\u001B[39;00m retrieval_index_dict.items()\n\u001B[32m---> \u001B[39m\u001B[32m74\u001B[39m ]\n\u001B[32m     76\u001B[39m results = {}\n\u001B[32m     78\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m ProcessPoolExecutor(max_workers=n_jobs) \u001B[38;5;28;01mas\u001B[39;00m executor:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\University\\7th_Semester\\MMSR25-26-Group-E\\.venv\\Lib\\site-packages\\joblib\\parallel.py:2072\u001B[39m, in \u001B[36mParallel.__call__\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m   2066\u001B[39m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[32m   2067\u001B[39m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[32m   2068\u001B[39m \u001B[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001B[39;00m\n\u001B[32m   2069\u001B[39m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[32m   2070\u001B[39m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[32m-> \u001B[39m\u001B[32m2072\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.return_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\University\\7th_Semester\\MMSR25-26-Group-E\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1682\u001B[39m, in \u001B[36mParallel._get_outputs\u001B[39m\u001B[34m(self, iterator, pre_dispatch)\u001B[39m\n\u001B[32m   1679\u001B[39m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[32m   1681\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backend.retrieval_context():\n\u001B[32m-> \u001B[39m\u001B[32m1682\u001B[39m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m._retrieve()\n\u001B[32m   1684\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[32m   1685\u001B[39m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[32m   1686\u001B[39m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[32m   1687\u001B[39m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n\u001B[32m   1688\u001B[39m     \u001B[38;5;28mself\u001B[39m._exception = \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\University\\7th_Semester\\MMSR25-26-Group-E\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1800\u001B[39m, in \u001B[36mParallel._retrieve\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1789\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.return_ordered:\n\u001B[32m   1790\u001B[39m     \u001B[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001B[39;00m\n\u001B[32m   1791\u001B[39m     \u001B[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   1795\u001B[39m     \u001B[38;5;66;03m# control only have to be done on the amount of time the next\u001B[39;00m\n\u001B[32m   1796\u001B[39m     \u001B[38;5;66;03m# dispatched job is pending.\u001B[39;00m\n\u001B[32m   1797\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m (nb_jobs == \u001B[32m0\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[32m   1798\u001B[39m         \u001B[38;5;28mself\u001B[39m._jobs[\u001B[32m0\u001B[39m].get_status(timeout=\u001B[38;5;28mself\u001B[39m.timeout) == TASK_PENDING\n\u001B[32m   1799\u001B[39m     ):\n\u001B[32m-> \u001B[39m\u001B[32m1800\u001B[39m         \u001B[43mtime\u001B[49m\u001B[43m.\u001B[49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m   1801\u001B[39m         \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[32m   1803\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m nb_jobs == \u001B[32m0\u001B[39m:\n\u001B[32m   1804\u001B[39m     \u001B[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001B[39;00m\n\u001B[32m   1805\u001B[39m     \u001B[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   1811\u001B[39m     \u001B[38;5;66;03m# timeouts before any other dispatched job has completed and\u001B[39;00m\n\u001B[32m   1812\u001B[39m     \u001B[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001B[39;00m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Audio (MFCC)",
   "id": "8f680504a48c6a2b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "audio_precision_dfs = calculate_unimodal_precision_dfs(feature_name='audio')\n",
    "\n",
    "target_dir = 'RetrievalAlgorithm/results/unimodal'\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "for norm_name, feature_name, sim_scores_df in tqdm(audio_precision_dfs, desc='Saving Audio Precision scores'):\n",
    "    output_path = os.path.join(target_dir, norm_name)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    output_path = os.path.join(output_path, f'unimodal_{norm_name}_{feature_name}_precision.parquet')\n",
    "    sim_scores_df.to_parquet(output_path, index=False)\n",
    "del audio_precision_dfs"
   ],
   "id": "f88fec00c80ea276",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Videoclip (VGG19)",
   "id": "47bdbf7e7f1d0b46"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "video_precision_dfs = calculate_unimodal_precision_dfs(feature_name='video')\n",
    "\n",
    "target_dir = 'RetrievalAlgorithm/results/unimodal'\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "for norm_name, feature_name, sim_scores_df in tqdm(video_precision_dfs, desc='Saving Video Precision scores'):\n",
    "    output_path = os.path.join(target_dir, norm_name)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    output_path = os.path.join(output_path, f'unimodal_{norm_name}_{feature_name}_precision.parquet')\n",
    "    sim_scores_df.to_parquet(output_path, index=False)\n",
    "del video_precision_dfs"
   ],
   "id": "98a788b97d16e3b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Multimodal (Early Fusion)",
   "id": "f7b9c8023c199e3a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def calculate_multimodal_precision_dfs(feature_name: str = 'audio_videoclips') -> Dict[str, pd.DataFrame]:\n",
    "    multimodal_precalculated_scores = dict()\n",
    "    precision_dfs = dict()\n",
    "\n",
    "    for norm_name in tqdm(norm_names, desc=f'Loading {feature_name} Precalculated scores'):\n",
    "        multimodal_precalculated_scores[norm_name]= pd.read_parquet(f'RetrievalAlgorithm/results/multimodal/early_fusion/{norm_name}/multimodal_{norm_name}_{feature_name}_similarity_scores.parquet')\n",
    "\n",
    "    print(f'Calculating {feature_name} Precision for each query ...')\n",
    "\n",
    "    for norm_name, precalculated_scores_df in multimodal_precalculated_scores.items():\n",
    "        print('='*100)\n",
    "        print('Normalization Name:', norm_name, '\\n')\n",
    "\n",
    "        precision_dfs[norm_name] = get_eval_metrics_for_each_query(\n",
    "            scores_df=precalculated_scores_df,\n",
    "            k_range=[5, 10, 20, 50, 100, 200],\n",
    "            genres_columns=genres_columns,\n",
    "            eval_songs_df=eval_songs_df,\n",
    "            metric_at_k=precision_at_k\n",
    "        )\n",
    "    return precision_dfs"
   ],
   "id": "8248148d9acee003",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Audio + Videoclips",
   "id": "d86abf61be2d2dc1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "audio_video_precision_dfs = calculate_multimodal_precision_dfs(feature_name='audio_videoclips')\n",
    "\n",
    "target_dir = 'RetrievalAlgorithm/results/multimodal/early_fusion'\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "for norm_name, feature_name, sim_scores_df in tqdm(audio_video_precision_dfs, desc='Saving Audio+Video Precision scores'):\n",
    "    output_path = os.path.join(target_dir, norm_name)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    output_path = os.path.join(output_path, f'multimodal_{norm_name}_{feature_name}_precision.parquet')\n",
    "    sim_scores_df.to_parquet(output_path, index=False)\n",
    "del audio_video_precision_dfs"
   ],
   "id": "3fbd69fe3157f99c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Lyrics + Audio",
   "id": "fd6a59edfcd41586"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lyrics_audio_precision_dfs = calculate_multimodal_precision_dfs(feature_name='lyrics_audio')\n",
    "\n",
    "target_dir = 'RetrievalAlgorithm/results/multimodal/early_fusion'\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "for norm_name, feature_name, sim_scores_df in tqdm(lyrics_audio_precision_dfs, desc='Saving Lyrics+Audio Precision scores'):\n",
    "    output_path = os.path.join(target_dir, norm_name)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    output_path = os.path.join(output_path, f'multimodal_{norm_name}_{feature_name}_precision.parquet')\n",
    "    sim_scores_df.to_parquet(output_path, index=False)\n",
    "del lyrics_audio_precision_dfs"
   ],
   "id": "a192a5909f2b90d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Lyrics + Videoclips",
   "id": "982ba196aa77429"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lyrics_videoclips_precision_dfs = calculate_multimodal_precision_dfs(feature_name='lyrics_videoclips')\n",
    "\n",
    "target_dir = 'RetrievalAlgorithm/results/multimodal/early_fusion'\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "for norm_name, feature_name, sim_scores_df in tqdm(lyrics_videoclips_precision_dfs, desc='Saving Audio+Video Precision scores'):\n",
    "    output_path = os.path.join(target_dir, norm_name)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    output_path = os.path.join(output_path, f'multimodal_{norm_name}_{feature_name}_precision.parquet')\n",
    "    sim_scores_df.to_parquet(output_path, index=False)\n",
    "del lyrics_videoclips_precision_dfs"
   ],
   "id": "33c3cee04afb30d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Lyrics + Audio + Videoclips",
   "id": "7096e956c263f52b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lyrics_audio_videoclips_precision_dfs = calculate_multimodal_precision_dfs(feature_name='lyrics_audio_videoclips')\n",
    "\n",
    "target_dir = 'RetrievalAlgorithm/results/multimodal/early_fusion'\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "for norm_name, feature_name, sim_scores_df in tqdm(lyrics_audio_videoclips_precision_dfs, desc='Saving Lyrics+Audio+Video Precision scores'):\n",
    "    output_path = os.path.join(target_dir, norm_name)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    output_path = os.path.join(output_path, f'multimodal_{norm_name}_{feature_name}_precision.parquet')\n",
    "    sim_scores_df.to_parquet(output_path, index=False)\n",
    "del lyrics_audio_videoclips_precision_dfs"
   ],
   "id": "72e52353f20c8541",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Multimodal (Late Fusion)",
   "id": "aac3dd58988dc0b3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def calculate_multimodal_max_score_precision_dfs() -> Dict[str, pd.DataFrame]:\n",
    "    multimodal_precalculated_scores = dict()\n",
    "    precision_dfs = dict()\n",
    "\n",
    "    for norm_name in tqdm(norm_names, desc=f'Loading Max Score Precalculated scores'):\n",
    "        multimodal_precalculated_scores[norm_name]= pd.read_parquet(f'RetrievalAlgorithm/results/multimodal/late_fusion/max_score/multimodal_{norm_name}_max_similarity_scores.parquet')\n",
    "\n",
    "    print(f'Calculating Max Score Precision for each query ...')\n",
    "\n",
    "    for norm_name, precalculated_scores_df in multimodal_precalculated_scores.items():\n",
    "        print('='*100)\n",
    "        print('Normalization Name:', norm_name, '\\n')\n",
    "\n",
    "        precision_dfs[norm_name] = get_eval_metrics_for_each_query(\n",
    "            scores_df=precalculated_scores_df,\n",
    "            k_range=[5, 10, 20, 50, 100, 200],\n",
    "            genres_columns=genres_columns,\n",
    "            eval_songs_df=eval_songs_df,\n",
    "            metric_at_k=precision_at_k\n",
    "        )\n",
    "    return precision_dfs"
   ],
   "id": "3645456af11fb82c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Max Score",
   "id": "2bfb26d1f1bb5013"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "max_scores_precision_dfs = calculate_multimodal_max_score_precision_dfs()\n",
    "\n",
    "target_dir = 'RetrievalAlgorithm/results/multimodal/late_fusion/max_score'\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "for norm_name, sim_scores_df in tqdm(max_scores_precision_dfs, desc='Saving precision scores'):\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "    output_path = os.path.join(target_dir, f'multimodal_{norm_name}_max_precision.parquet')\n",
    "    sim_scores_df.to_parquet(output_path, index=False)\n",
    "del max_scores_precision_dfs"
   ],
   "id": "b768058eed4b6544",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
